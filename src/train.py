import os
import time 
import numpy as np
import torch
import torch.nn as nn
from torch.utils.data import DataLoader
from torch.utils.tensorboard import SummaryWriter
import matplotlib.pyplot as plt
from typing import Optional, Tuple, List
from src.config import *
from src.config import TrainingConfig, DEFAULT_TRAINING_CONFIG
from src.model import SimpleLSTM
from src.dataset import MaichartDataset, collate_fn

def train_model(model, train_loader, val_loader, config: TrainingConfig = None, 
                experiment_name: Optional[str] = None, log_dir: Optional[str] = None) -> Tuple[List[float], List[float]]:
    """
    æ”¹è¿›çš„æ¨¡å‹è®­ç»ƒå‡½æ•°ï¼ŒåŒ…å«éªŒè¯é›†ç›‘æ§ã€æ—©åœæœºåˆ¶ã€å­¦ä¹ ç‡è°ƒåº¦å’Œ TensorBoard æ—¥å¿—è®°å½•ã€‚
    
    Args:
        model (nn.Module): è¦è®­ç»ƒçš„ PyTorch æ¨¡å‹
        train_loader (DataLoader): è®­ç»ƒæ•°æ®åŠ è½½å™¨ï¼ŒåŒ…å« (sequences, labels) æˆ– (sequences, labels, padding_mask)
        val_loader (DataLoader): éªŒè¯æ•°æ®åŠ è½½å™¨ï¼Œæ ¼å¼åŒè®­ç»ƒæ•°æ®åŠ è½½å™¨
        config (TrainingConfig, optional): è®­ç»ƒé…ç½®å¯¹è±¡ã€‚é»˜è®¤ä½¿ç”¨ DEFAULT_TRAINING_CONFIG
        experiment_name (str, optional): å®éªŒåç§°ï¼Œç”¨äº TensorBoard æ—¥å¿—
        log_dir (str, optional): TensorBoard æ—¥å¿—ç›®å½•
    
    Returns:
        tuple[list, list]: åŒ…å«ä¸¤ä¸ªåˆ—è¡¨çš„å…ƒç»„
            - train_losses (list): æ¯ä¸ª epoch çš„å¹³å‡è®­ç»ƒæŸå¤±
            - val_losses (list): æ¯ä¸ª epoch çš„å¹³å‡éªŒè¯æŸå¤±
    """
    if config is None:
        config = DEFAULT_TRAINING_CONFIG
    
    criterion = nn.MSELoss()
    optimizer = torch.optim.Adam(
        model.parameters(), 
        lr=config.learning_rate, 
        weight_decay=config.weight_decay
    )
    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(
        optimizer, 
        config.scheduler_mode, 
        patience=config.scheduler_patience, 
        factor=config.scheduler_factor
    )
    
    # åˆå§‹åŒ– TensorBoard Writer
    writer = None
    if log_dir and experiment_name:
        tb_log_dir = os.path.join(log_dir, experiment_name)
        writer = SummaryWriter(tb_log_dir)
        print(f"TensorBoard æ—¥å¿—ç›®å½•: {tb_log_dir}")
    
    best_val_loss = float('inf')
    patience_counter = 0
    
    train_losses = []
    val_losses = []
    
    # æ€»è®­ç»ƒå¼€å§‹æ—¶é—´
    total_start_time = time.time()
    
    for epoch in range(config.num_epochs):
        # è®­ç»ƒé˜¶æ®µ
        model.train()
        train_loss = 0.0
        train_batch_times = []
        print(f"Epoch [{epoch+1}/{config.num_epochs}] - è®­ç»ƒé˜¶æ®µ")
        print("-" * 60)
        
        for batch_idx, (sequences, labels) in enumerate(train_loader):
            batch_start_time = time.time()
            
            # å°†æ•°æ®ç§»åŠ¨åˆ° GPU
            sequences, labels = sequences.to(DEVICE), labels.to(DEVICE)
            
            optimizer.zero_grad()
            outputs = model(sequences)
            loss = criterion(outputs, labels)
            loss.backward()
            
            # æ¢¯åº¦è£å‰ªé˜²æ­¢æ¢¯åº¦çˆ†ç‚¸
            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=config.grad_clip_max_norm)
            
            optimizer.step()
            batch_time = time.time() - batch_start_time
            train_batch_times.append(batch_time)
            train_loss += loss.item()            # æ¯10ä¸ªbatchè¾“å‡ºä¸€æ¬¡è¿›åº¦ï¼ˆå¯è°ƒæ•´é¢‘ç‡ï¼‰
            if (batch_idx + 1) % config.log_interval == 0 or (batch_idx + 1) == len(train_loader):
                avg_batch_time = np.mean(train_batch_times[-10:])  # æœ€è¿‘10ä¸ªbatchçš„å¹³å‡æ—¶é—´
                print(f"  Batch [{batch_idx+1:4d}/{len(train_loader):4d}] | "
                      f"Loss: {loss.item():.4f} | "
                      f"Batch Time: {batch_time:.2f}s | "
                      f"Avg Time: {avg_batch_time:.2f}s | "
                      f"Seq Shape: {sequences.shape}")
        
        avg_train_loss = train_loss / len(train_loader)
        train_losses.append(avg_train_loss)
        
        # è®°å½•è®­ç»ƒæŸå¤±åˆ° TensorBoard
        if writer:
            writer.add_scalar('Loss/Train', avg_train_loss, epoch)
            writer.add_scalar('Learning_Rate', optimizer.param_groups[0]['lr'], epoch)
            
            # è®°å½•æ¨¡å‹å‚æ•°åˆ†å¸ƒ
            for name, param in model.named_parameters():
                if param.grad is not None:                    
                    writer.add_histogram(f'Parameters/{name}', param, epoch)
                    writer.add_histogram(f'Gradients/{name}', param.grad, epoch)
          # === éªŒè¯é˜¶æ®µ ===
        print(f"\nEpoch [{epoch+1}/{config.num_epochs}] - éªŒè¯é˜¶æ®µ")
        model.eval()
        val_loss = 0.0
        with torch.no_grad():
            for sequences, labels in val_loader:
                # å°†æ•°æ®ç§»åŠ¨åˆ° GPU
                sequences, labels = sequences.to(DEVICE), labels.to(DEVICE)
                
                outputs = model(sequences)
                loss = criterion(outputs, labels)
                val_loss += loss.item()
        
        avg_val_loss = val_loss / len(val_loader)
        val_losses.append(avg_val_loss)
        
        # è®°å½•éªŒè¯æŸå¤±åˆ° TensorBoard
        if writer:
            writer.add_scalar('Loss/Validation', avg_val_loss, epoch)
        
        # å­¦ä¹ ç‡è°ƒåº¦
        scheduler.step(avg_val_loss)
        
        # æ—©åœæ£€æŸ¥
        if avg_val_loss < best_val_loss:
            best_val_loss = avg_val_loss
            patience_counter = 0
            # ä¿å­˜æœ€ä½³æ¨¡å‹
            model_save_path = os.path.join(MODEL_DIR, "best_model.pth")
            torch.save(model.state_dict(), model_save_path)
            print(f"æ–°çš„æœ€ä½³æ¨¡å‹å·²ä¿å­˜ (éªŒè¯æŸå¤±: {best_val_loss:.6f})")
        else:
            patience_counter += 1
            print(f"æ—©åœè®¡æ•°å™¨: {patience_counter}/{config.early_stop_patience}")
        
        print(f"Epoch [{epoch+1}/{config.num_epochs}] - Train Loss: {avg_train_loss:.4f}, Val Loss: {avg_val_loss:.4f}")

        # ä¼°ç®—å‰©ä½™æ—¶é—´
        elapsed_time = time.time() - total_start_time
        avg_epoch_time = elapsed_time / (epoch + 1)
        remaining_epochs = config.num_epochs - (epoch + 1)
        estimated_remaining_time = avg_epoch_time * remaining_epochs
        print(f"  å·²ç”¨æ—¶é—´: {elapsed_time/60:.1f}åˆ†é’Ÿ | é¢„è®¡å‰©ä½™: {estimated_remaining_time/60:.1f}åˆ†é’Ÿ")
        print(f"{'='*60}")
        
        if patience_counter >= config.early_stop_patience:
            print(f"Early stopping at epoch {epoch+1}")
            break
    
    total_training_time = time.time() - total_start_time
    print(f"\nğŸ‰ è®­ç»ƒå®Œæˆ!")
    print(f"æ€»è®­ç»ƒæ—¶é—´: {total_training_time/60:.1f} åˆ†é’Ÿ")
    print(f"æœ€ä½³éªŒè¯æŸå¤±: {best_val_loss:.6f}")
    
    # å…³é—­ TensorBoard Writer
    if writer:
        writer.close()
        print(f"TensorBoard æ—¥å¿—å·²ä¿å­˜åˆ°: {writer.log_dir}")
    
    return train_losses, val_losses

def evaluate_model(model, data_loader, config: TrainingConfig = None, writer=None, epoch=None, phase=""):
    """å…¨é¢è¯„ä¼°æ¨¡å‹æ€§èƒ½ï¼Œæ”¯æŒ TensorBoard è®°å½•"""
    if config is None:
        config = DEFAULT_TRAINING_CONFIG
        
    model.eval()
    predictions = []
    true_values = []
    
    with torch.no_grad():
        for sequences, labels in data_loader:
            sequences, labels = sequences.to(DEVICE), labels.to(DEVICE)
            outputs = model(sequences)
            predictions.extend(outputs.cpu().numpy().flatten())
            true_values.extend(labels.cpu().numpy().flatten())
    
    predictions = np.array(predictions)
    true_values = np.array(true_values)
    
    # è®¡ç®—å„ç§æŒ‡æ ‡
    mse = np.mean((predictions - true_values) ** 2)
    mae = np.mean(np.abs(predictions - true_values))
    r2 = 1 - np.sum((true_values - predictions) ** 2) / np.sum((true_values - np.mean(true_values)) ** 2)
    
    # å‡†ç¡®æ€§åˆ†æï¼ˆåœ¨ä¸åŒè¯¯å·®èŒƒå›´å†…çš„æ¯”ä¾‹ï¼‰
    accuracy_results = {}
    accuracy_thresholds = config.accuracy_thresholds
    for threshold in accuracy_thresholds:
        accuracy_results[f'acc_{str(threshold).replace(".", "")}'] = np.mean(np.abs(predictions - true_values) <= threshold)    
    print(f"è¯„ä¼°ç»“æœ {phase}:")
    print(f"  MSE: {mse:.4f}")
    print(f"  MAE: {mae:.4f}")
    print(f"  RÂ²: {r2:.4f}")
    for threshold in accuracy_thresholds:
        acc_key = f'acc_{str(threshold).replace(".", "")}'
        print(f"  Â±{threshold}å‡†ç¡®ç‡: {accuracy_results[acc_key]:.3f}")
    
    # è®°å½•åˆ° TensorBoard
    if writer and epoch is not None:
        prefix = f"Metrics/{phase}" if phase else "Metrics"
        writer.add_scalar(f'{prefix}/MSE', mse, epoch)
        writer.add_scalar(f'{prefix}/MAE', mae, epoch)
        writer.add_scalar(f'{prefix}/R2', r2, epoch)
        
        # è®°å½•å‡†ç¡®ç‡æŒ‡æ ‡
        for threshold in accuracy_thresholds:
            acc_key = f'acc_{str(threshold).replace(".", "")}'
            threshold_str = str(threshold).replace(".", "_")
            writer.add_scalar(f'{prefix}/Accuracy_{threshold_str}', accuracy_results[acc_key], epoch)
        
        # è®°å½•é¢„æµ‹åˆ†å¸ƒ
        writer.add_histogram(f'{prefix}/Predictions', predictions, epoch)
        writer.add_histogram(f'{prefix}/True_Values', true_values, epoch)
        writer.add_histogram(f'{prefix}/Prediction_Errors', predictions - true_values, epoch)
        
        # åˆ›å»ºå¹¶è®°å½•æ•£ç‚¹å›¾
        if len(predictions) <= config.max_scatter_points:  # é¿å…å›¾åƒè¿‡äºå¯†é›†
            scatter_fig = create_prediction_scatter_plot(
                predictions, true_values, 
                title=f"Predictions vs True Values {phase}"
            )
            writer.add_figure(f'{prefix}/Prediction_Scatter', scatter_fig, epoch)
            plt.close(scatter_fig)  # é‡Šæ”¾å†…å­˜    
    return {
        'mse': mse, 'mae': mae, 'r2': r2,
        **accuracy_results,
        'predictions': predictions, 'true_values': true_values
    }

import json
import datetime
from datetime import datetime

def save_experiment_log(model, train_losses, val_losses, train_results, test_results, config):
    """ä¿å­˜å®éªŒè®°å½•"""
    
    # åˆ›å»ºå®éªŒæ—¥å¿—ç›®å½•
    log_dir = os.path.join(BASE_DIR, "experiment_logs")
    os.makedirs(log_dir, exist_ok=True)
    
    timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
    
    # å®éªŒé…ç½®å’Œç»“æœ
    experiment_log = {
        'timestamp': timestamp,
        'model_config': config,
        'model_parameters': sum(p.numel() for p in model.parameters()),
        'training': {
            'num_epochs': len(train_losses),
            'final_train_loss': train_losses[-1],
            'final_val_loss': val_losses[-1],
            'best_val_loss': min(val_losses),
            'train_losses': train_losses,
            'val_losses': val_losses
        },
        'evaluation': {
            'train_results': {k: float(v) if isinstance(v, (int, float, np.number)) else str(v) 
                            for k, v in train_results.items() if k not in ['predictions', 'true_values']},
            'test_results': {k: float(v) if isinstance(v, (int, float, np.number)) else str(v) 
                           for k, v in test_results.items() if k not in ['predictions', 'true_values']}
        }
    }
    
    # ä¿å­˜æ—¥å¿—
    log_file = os.path.join(log_dir, f"experiment_{timestamp}.json")
    with open(log_file, 'w', encoding='utf-8') as f:
        json.dump(experiment_log, f, indent=2, ensure_ascii=False)
    
    print(f"å®éªŒæ—¥å¿—å·²ä¿å­˜: {log_file}")
    return log_file

def train_complete_pipeline():
    """å®Œæ•´çš„è®­ç»ƒæµç¨‹ï¼ŒåŒ…å« TensorBoard æ—¥å¿—è®°å½•"""

    # å®éªŒé…ç½®
    config = TrainingConfig()
    print(f"å®éªŒé…ç½®: {config.to_dict()}")
    print("="*80)

    # è®¾ç½® TensorBoard æ—¥å¿—
    timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
    experiment_name = f"experiment_{timestamp}"
    tb_log_dir = os.path.join(BASE_DIR, "tensorboard_logs")
    os.makedirs(tb_log_dir, exist_ok=True)
    print(f"TensorBoard å®éªŒåç§°: {experiment_name}")

    # åˆ›å»ºæ•°æ®é›†
    print("\nåˆ›å»ºæ•°æ®é›†...")
    dataset_start_time = time.time()
    train_dataset = MaichartDataset(SERIALIZED_DIR, TRAIN_DATA_PATH)
    test_dataset = MaichartDataset(SERIALIZED_DIR, TEST_DATA_PATH)
    dataset_time = time.time() - dataset_start_time
    print(f"æ•°æ®é›†åˆ›å»ºå®Œæˆ ({dataset_time:.3f}s)")
    print(f"è®­ç»ƒé›†å¤§å°: {len(train_dataset)}, æµ‹è¯•é›†å¤§å°: {len(test_dataset)}")
    
    # åˆ›å»ºæ•°æ®åŠ è½½å™¨
    print("\nåˆ›å»ºæ•°æ®åŠ è½½å™¨...")
    loader_start_time = time.time()

    train_loader = DataLoader(
        train_dataset,
        batch_size=config.batch_size,
        shuffle=True,
        collate_fn=collate_fn,
        num_workers=0
    )

    # æµ‹è¯•åŠ è½½å™¨ä¸éœ€è¦åˆ†æ¡¶æˆ–æ‰“ä¹±
    test_loader = DataLoader(
        test_dataset,
        batch_size=config.batch_size,
        shuffle=False,
        collate_fn=collate_fn,
        num_workers=0
    )
    loader_time = time.time() - loader_start_time
    print(f"æ•°æ®åŠ è½½å™¨åˆ›å»ºå®Œæˆ ({loader_time:.3f}s)")
    print(f"è®­ç»ƒæ‰¹æ¬¡æ•°: {len(train_loader)}, æµ‹è¯•æ‰¹æ¬¡æ•°: {len(test_loader)}")    # åˆ›å»ºæ¨¡å‹
    print("\nåˆ›å»ºæ¨¡å‹...")
    model_start_time = time.time()
    model = SimpleLSTM(
        config.input_size, 
        config.hidden_size, 
        config.output_size, 
        config.num_layers
    )
    model_time = time.time() - model_start_time
    param_count = sum(p.numel() for p in model.parameters())
    print(f"æ¨¡å‹åˆ›å»ºå®Œæˆ ({model_time:.3f}s)")
    print(f"æ¨¡å‹å‚æ•°æ•°é‡: {param_count:,}")
    print(f"æ¨¡å‹è®¾å¤‡: {next(model.parameters()).device}")

    # åˆ›å»º TensorBoard Writer å¹¶è®°å½•æ¨¡å‹ç»“æ„
    writer = SummaryWriter(os.path.join(tb_log_dir, experiment_name))
    
    # è®°å½•æ¨¡å‹ç»“æ„å›¾ï¼ˆä½¿ç”¨ä¸€ä¸ªæ ·æœ¬æ•°æ®ï¼‰
    try:
        sample_input, _ = next(iter(train_loader))
        sample_input = sample_input.to(DEVICE)
        writer.add_graph(model, sample_input)
        print("æ¨¡å‹ç»“æ„å›¾å·²è®°å½•åˆ° TensorBoard")
    except Exception as e:
        print(f"è®°å½•æ¨¡å‹ç»“æ„å›¾å¤±è´¥: {e}")    # è®­ç»ƒæ¨¡å‹
    print("\nå¼€å§‹è®­ç»ƒ...")
    train_losses, val_losses = train_model(
        model, train_loader, test_loader, 
        config=config,
        experiment_name=experiment_name,
        log_dir=tb_log_dir
    )
    
    # åŠ è½½æœ€ä½³æ¨¡å‹å¹¶è¯„ä¼°
    model.load_state_dict(torch.load(os.path.join(MODEL_DIR, "best_model.pth")))
    print("\n=== è®­ç»ƒé›†è¯„ä¼° ===")
    train_results = evaluate_model(model, train_loader, config)
    print("\n=== æµ‹è¯•é›†è¯„ä¼° ===")
    test_results = evaluate_model(model, test_loader, config)# ä¿å­˜å®éªŒè®°å½•
    log_file = save_experiment_log(model, train_losses, val_losses, train_results, test_results, config.to_dict())


    return model, train_losses, val_losses, train_results, test_results

def create_prediction_scatter_plot(predictions, true_values, title="Predictions vs True Values"):
    """åˆ›å»ºé¢„æµ‹å€¼ä¸çœŸå®å€¼çš„æ•£ç‚¹å›¾"""
    plt.figure(figsize=(8, 8))
    plt.scatter(true_values, predictions, alpha=0.6, s=20)
    
    # æ·»åŠ å®Œç¾é¢„æµ‹çº¿ (y=x)
    min_val = min(min(predictions), min(true_values))
    max_val = max(max(predictions), max(true_values))
    plt.plot([min_val, max_val], [min_val, max_val], 'r--', linewidth=2, label='Perfect Prediction')
    
    plt.xlabel('True Values')
    plt.ylabel('Predictions')
    plt.title(title)
    plt.legend()
    plt.grid(True, alpha=0.3)
    
    # ä½¿ç”¨ plt.tight_layout() ç¡®ä¿å¸ƒå±€ç´§å‡‘
    plt.tight_layout()
    
    return plt.gcf()
