{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "95f98cbe",
   "metadata": {},
   "source": [
    "# maimai 谱面难度预测"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d79795d1",
   "metadata": {},
   "source": [
    "## 1. 导入所需库"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a4e1287",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1db9c020",
   "metadata": {},
   "source": [
    "## 2. 加载数据"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97b7ded5",
   "metadata": {},
   "source": [
    "### 2.1 加载并解析 maidata.txt\n",
    "\n",
    "我们使用外部工具 `SimaiSerializerFromMajdataEdit.exe` 来将 `maidata.txt` 格式的谱面文件解析并序列化为 JSON 文件。\n",
    "\n",
    "**使用方法:**\n",
    "\n",
    "在终端中执行以下命令，它会将 `data\\maichart-converts` 目录下的所有谱面处理并输出到 `data\\serialized` 目录。\n",
    "\n",
    "```bash\n",
    "src\\serializer\\src\\bin\\Release\\net8.0\\SimaiSerializerFromMajdataEdit.exe data\\maichart-converts data\\serialized\n",
    "```\n",
    "\n",
    "该工具的通用命令格式为： `SimaiSerializerFromMajdataEdit.exe <输入文件或目录> <输出目录>`\n",
    "\n",
    "执行完毕后，我们就可以在下一步中加载这些生成的 JSON 文件。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "502d9855",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import subprocess\n",
    "\n",
    "# 路径定义\n",
    "exe_path = r'src\\serializer\\src\\bin\\Release\\net8.0\\SimaiSerializerFromMajdataEdit.exe'\n",
    "input_dir = r'data\\maichart-converts'\n",
    "output_dir = r'data\\serialized'\n",
    "\n",
    "# 构建并显示命令\n",
    "command = f'\"{exe_path}\" \"{input_dir}\" \"{output_dir}\"'\n",
    "print(f\"即将执行的命令: {command}\")\n",
    "\n",
    "# 用户确认\n",
    "if input(\"请确认是否要执行此命令 (y/n): \").strip().lower() != 'y':\n",
    "    print(\"操作已取消\")\n",
    "    exit()\n",
    "\n",
    "try:\n",
    "    # 执行命令\n",
    "    print(\"开始执行命令...\")\n",
    "    result = subprocess.run(command, shell=True, check=True, \n",
    "                          stdout=subprocess.PIPE, stderr=subprocess.PIPE, text=True)\n",
    "    \n",
    "    print(\"命令执行成功！\")\n",
    "    print(\"输出结果:\")\n",
    "    print(result.stdout)\n",
    "    \n",
    "except subprocess.CalledProcessError as e:\n",
    "    print(\"错误信息:\", e.stderr)\n",
    "except Exception as e:\n",
    "    print(f\"发生异常: {str(e)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e50b50b8",
   "metadata": {},
   "source": [
    "### 2.2 加载谱面标签数据\n",
    "请将你的谱面标签数据（如 CSV 文件）放置在 `data` 目录下，并在此处加载。\n",
    "标签数据应至少包含 `song_id` 和 `difficulty_constant` 两列。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49f5452c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# label_df = pd.read_csv('../data/your_labels.csv')\n",
    "# print(label_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6c8e756",
   "metadata": {},
   "source": [
    "## 3. 特征工程"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dd0e33f",
   "metadata": {},
   "source": [
    "在这一步，我们将从解析后的谱面数据中提取特征。特征可以包括：\n",
    "\n",
    "- Note 总数\n",
    "- BPM 变化\n",
    "- 特定 Note 类型（Tap, Hold, Slide）的数量\n",
    "- Note 密度\n",
    "- ...等等"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "982a8fee",
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_engineering(chart_data):\n",
    "    features = []\n",
    "    for chart in chart_data:\n",
    "        # 在这里实现你的特征提取逻辑\n",
    "        feature_vector = {\n",
    "            'song_id': chart.get('song_id'), # 假设解析后的数据中有 song_id\n",
    "            'note_count': len(chart.get('notes', [])), # 示例特征\n",
    "            # 添加更多特征...\n",
    "        }\n",
    "        features.append(feature_vector)\n",
    "    return pd.DataFrame(features)\n",
    "\n",
    "# # 加载之前保存的 JSON 数据\n",
    "# with open('../data/chart_data.json', 'r', encoding='utf-8') as f:\n",
    "#     chart_data_json = json.load(f)\n",
    "#\n",
    "# feature_df = feature_engineering(chart_data_json)\n",
    "# print(feature_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ec37d65",
   "metadata": {},
   "source": [
    "## 4. 数据预处理与模型构建"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77c3ed6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 合并特征和标签\n",
    "# full_df = pd.merge(feature_df, label_df, on='song_id')\n",
    "#\n",
    "# # 分离特征和目标变量\n",
    "# X = full_df.drop(['song_id', 'difficulty_constant'], axis=1).values\n",
    "# y = full_df['difficulty_constant'].values\n",
    "#\n",
    "# # 数据标准化\n",
    "# scaler = StandardScaler()\n",
    "# X_scaled = scaler.fit_transform(X)\n",
    "#\n",
    "# # 划分训练集和测试集\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)\n",
    "#\n",
    "# # 转换为 PyTorch Tensors\n",
    "# X_train_tensor = torch.tensor(X_train, dtype=torch.float32)\n",
    "# y_train_tensor = torch.tensor(y_train, dtype=torch.float32).view(-1, 1)\n",
    "# X_test_tensor = torch.tensor(X_test, dtype=torch.float32)\n",
    "# y_test_tensor = torch.tensor(y_test, dtype=torch.float32).view(-1, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a57606c6",
   "metadata": {},
   "source": [
    "### 4.1 定义模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e18abac",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DifficultyPredictor(nn.Module):\n",
    "    def __init__(self, input_features):\n",
    "        super(DifficultyPredictor, self).__init__()\n",
    "        self.layer1 = nn.Linear(input_features, 128)\n",
    "        self.layer2 = nn.Linear(128, 64)\n",
    "        self.output_layer = nn.Linear(64, 1)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.relu(self.layer1(x))\n",
    "        x = self.relu(self.layer2(x))\n",
    "        x = self.output_layer(x)\n",
    "        return x\n",
    "\n",
    "# model = DifficultyPredictor(X_train_tensor.shape[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83eeaf44",
   "metadata": {},
   "source": [
    "## 5. 模型训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07f4c4d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 定义损失函数和优化器\n",
    "# criterion = nn.MSELoss()\n",
    "# optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "#\n",
    "# # 训练循环\n",
    "# epochs = 100\n",
    "# for epoch in range(epochs):\n",
    "#     model.train()\n",
    "#     optimizer.zero_grad()\n",
    "#     outputs = model(X_train_tensor)\n",
    "#     loss = criterion(outputs, y_train_tensor)\n",
    "#     loss.backward()\n",
    "#     optimizer.step()\n",
    "#\n",
    "#     if (epoch+1) % 10 == 0:\n",
    "#         print(f'Epoch [{epoch+1}/{epochs}], Loss: {loss.item():.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19e27cee",
   "metadata": {},
   "source": [
    "## 6. 模型评估"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0c76b12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.eval()\n",
    "# with torch.no_grad():\n",
    "#     predictions = model(X_test_tensor)\n",
    "#     test_loss = criterion(predictions, y_test_tensor)\n",
    "#     print(f'Test Loss: {test_loss.item():.4f}')\n",
    "#\n",
    "# # 可以在这里添加更详细的评估指标，例如 MAE, R^2 等"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f003fee0",
   "metadata": {},
   "source": [
    "## 7. 结果分析与迭代"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3bf24c6",
   "metadata": {},
   "source": [
    "分析模型的预测结果，与真实定数进行比较。\n",
    "\n",
    "思考以下问题：\n",
    "- 模型的误差主要来自哪些谱面？\n",
    "- 是否有必要调整特征工程的方案？\n",
    "- 是否需要更复杂的模型结构？\n",
    "\n",
    "根据分析结果，回到前面的步骤进行迭代优化。"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
