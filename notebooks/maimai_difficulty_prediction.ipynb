{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "95f98cbe",
   "metadata": {},
   "source": [
    "# maimai 谱面难度预测 - 基于 LSTM 的时序建模\n",
    "\n",
    "本项目使用 LSTM 神经网络直接处理谱面的 note 序列数据，将每个 note 的时间戳和类型等信息作为时序特征输入模型，预测谱面的难度定数。\n",
    "\n",
    "**核心思路**：将谱面视为时间序列，每个 note 包含时间戳、类型、位置等属性，通过 LSTM 学习 note 序列的时序特征来预测难度。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d79795d1",
   "metadata": {},
   "source": [
    "## 1. 导入所需库"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a4e1287",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "import csv\n",
    "import os\n",
    "import sys"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1db9c020",
   "metadata": {},
   "source": [
    "## 2. 数据处理与序列化\n",
    "\n",
    "数据处理分为两个主要步骤：\n",
    "1. **谱面解析**：将 maidata.txt 格式解析为结构化的 note 序列数据\n",
    "2. **序列预处理**：将 note 序列转换为适合 LSTM 输入的格式\n",
    "\n",
    "**核心理念**：每个谱面是一个时间序列，包含按时间顺序排列的 note 序列。每个 note 具有时间戳、类型、位置等属性。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e7bf94d",
   "metadata": {},
   "source": [
    "### 2.1 解析 maidata.txt\n",
    "\n",
    "我们使用外部工具 `SimaiSerializerFromMajdataEdit.exe` 来将 `maidata.txt` 格式的谱面文件解析并序列化为 JSON 文件。\n",
    "\n",
    "数据来源：maichart-converts\n",
    "\n",
    "**使用方法:**\n",
    "\n",
    "在终端中执行以下命令，它会将 `data\\maichart-converts` 目录下的所有谱面处理并输出到 `data\\serialized` 目录。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "83aba23b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "src\\serializer\\src\\bin\\Release\\net8.0\\SimaiSerializerFromMajdataEdit.exe data\\maichart-converts data\\serialized\n"
     ]
    }
   ],
   "source": [
    "command = (\n",
    "    r\"src\\serializer\\src\\bin\\Release\\net8.0\\SimaiSerializerFromMajdataEdit.exe \"\n",
    "    r\"data\\maichart-converts data\\serialized\"\n",
    ")\n",
    "print(command)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ebc6c18",
   "metadata": {},
   "source": [
    "该工具的通用命令格式为： `SimaiSerializerFromMajdataEdit.exe <输入文件或目录> <输出目录>`\n",
    "\n",
    "执行完毕后，我们将得到包含 note 序列数据的 JSON 文件，每个文件对应一个特定难度的谱面。\n",
    "\n",
    "**TODO**：\n",
    "- 运行序列化工具并检查输出结果\n",
    "- 验证生成的 JSON 文件结构\n",
    "- 统计不同谱面的 note 数量分布，为序列长度标准化做准备\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e50b50b8",
   "metadata": {},
   "source": [
    "### 2.2 处理谱面标签数据\n",
    "\n",
    "从 maimai-songs 库的 songs.json 中提取训练标签：\n",
    "- **歌曲ID**：song_id（json中为id）\n",
    "- **难度序号**：level_index（在json中并未显式标明，charts中依次对应level_index 1-5的数据）\n",
    "- **难度定数**：difficulty_constant（json中为level）- 这是我们的预测目标\n",
    "\n",
    "**TODO**：\n",
    "- 提取标签数据并与序列化的谱面数据进行匹配\n",
    "- 处理缺失的难度定数（null值）\n",
    "- 过滤掉六位数ID的宴谱数据\n",
    "- 从 flevel.json 中获取拟合等级数据作为辅助信息\n",
    "- 验证标签与谱面文件的一一对应关系"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49f5452c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "尝试读取JSON文件: d:\\wushuopei\\code\\BMK-mdp\\data\\maimai-songs\\songs.json\n",
      "成功提取 6442 条记录，已写入 d:\\wushuopei\\code\\BMK-mdp\\data\\song_info.csv\n"
     ]
    }
   ],
   "source": [
    "def extract_song_info(json_file_path):\n",
    "    # 添加文件存在性检查\n",
    "    if not os.path.exists(json_file_path):\n",
    "        print(f\"错误：文件不存在 - {json_file_path}\")\n",
    "        print(\"请检查：\")\n",
    "        print(f\"1. 文件实际位置（当前工作目录：{os.getcwd()}）\")\n",
    "        print(\"2. 路径是否正确（注意大小写）\")\n",
    "        sys.exit(1)  # 退出程序\n",
    "    \n",
    "    # 读取JSON文件\n",
    "    with open(json_file_path, 'r', encoding='utf-8') as json_file:\n",
    "        songs_data = json.load(json_file)\n",
    "    \n",
    "    # 提取所需信息\n",
    "    extracted_info = []\n",
    "    for song in songs_data:\n",
    "        song_id = song.get('id')\n",
    "        charts = song.get('charts', [])\n",
    "        \n",
    "        for level_index, chart in enumerate(charts, start=1):\n",
    "            difficulty_constant = chart.get('level')\n",
    "            extracted_info.append({\n",
    "                'song_id': song_id,\n",
    "                'level_index': level_index,\n",
    "                'difficulty_constant': difficulty_constant\n",
    "            })\n",
    "    \n",
    "    return extracted_info\n",
    "\n",
    "def write_to_csv(data, csv_file_path):\n",
    "    # 创建输出目录（如果不存在）\n",
    "    os.makedirs(os.path.dirname(csv_file_path), exist_ok=True)\n",
    "    \n",
    "    # 写入CSV文件\n",
    "    with open(csv_file_path, 'w', newline='', encoding='utf-8') as csv_file:\n",
    "        fieldnames = ['song_id', 'level_index', 'difficulty_constant']\n",
    "        writer = csv.DictWriter(csv_file, fieldnames=fieldnames)\n",
    "        \n",
    "        writer.writeheader()\n",
    "        for item in data:\n",
    "            writer.writerow(item)\n",
    "\n",
    "# 使用跨平台路径处理\n",
    "base_dir = os.path.dirname(os.path.abspath(''))  # 获取当前工作目录\n",
    "json_path = os.path.join(base_dir, \"data\", \"maimai-songs\", \"songs.json\")  # 修正路径\n",
    "csv_path = os.path.join(base_dir, \"data\", \"song_info.csv\")  # 修正路径\n",
    "\n",
    "# print(f\"尝试读取JSON文件: {json_path}\")\n",
    "# extracted_data = extract_song_info(json_path)\n",
    "# write_to_csv(extracted_data, csv_path)\n",
    "# print(f\"成功提取 {len(extracted_data)} 条记录，已写入 {csv_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6c8e756",
   "metadata": {},
   "source": [
    "## 3. 序列预处理与特征编码\n",
    "\n",
    "不同于传统的特征工程方法，我们直接使用原始的 note 序列数据。主要任务是将 note 属性转换为数值向量，并处理序列长度不一致的问题。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8934d3c1",
   "metadata": {},
   "source": [
    "### 3.0 构建自定义Dataset类\n",
    "我们创建一个自定义Dataset，存储json文件的位置以及csv的位置。\n",
    "在Dataset中，需要实现：\n",
    "1. `__init__()`：初始化函数，传入serialized目录以及csv文件位置。\n",
    "    - 需要存储每个json的路径\n",
    "2. `__len__()`：返回数据集的长度。\n",
    "3. `__getitem__()`：返回数据集中的第i个样本。直接返回tensor\n",
    "    - 在`__getitem__()`中才读取json文件，并返回tensor\n",
    "    - 读取json文件，然后再去csv中找对应`(song_id,level_index)`的行\n",
    "    - index顺序是什么"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "590d3594",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "class MaichartDataset(Dataset):\n",
    "    def __init__(self, serialized_dir, labels_csv):\n",
    "        self.serialized_dir = serialized_dir\n",
    "        self.labels_data = pd.read_csv(labels_csv)\n",
    "\n",
    "        cleaned_data = self.labels_data.dropna(subset=['song_id', 'level_index', 'difficulty_constant'])\n",
    "\n",
    "        self.label_map = (\n",
    "            cleaned_data.astype({'song_id': int, 'level_index': int, 'difficulty_constant': float})\n",
    "            .set_index(['song_id', 'level_index'])['difficulty_constant']\n",
    "            .to_dict()\n",
    "        )\n",
    "\n",
    "        # TouchArea映射\n",
    "        self.touch_area_mapping = {\" \": 0, \"A\": 1, \"D\": 2, \"E\": 3, \"B\": 4, \"C\": 5} # 从外到内\n",
    "\n",
    "        # 初始化编码器\n",
    "        self._setup_encoders()\n",
    "        \n",
    "        # 获取JSON文件路径\n",
    "        self.json_paths = glob.glob(os.path.join(serialized_dir, \"*.json\"))\n",
    "\n",
    "    def _setup_encoders(self):\n",
    "        \"\"\"设置note类型和位置的编码器\"\"\"\n",
    "        # Note类型编码器\n",
    "        NOTE_TYPES = ['Tap', 'Hold', 'Slide', 'Touch', 'TouchHold']\n",
    "        self.note_type_encoder = OneHotEncoder(\n",
    "            sparse_output=False,\n",
    "            dtype=np.float32,\n",
    "            handle_unknown='ignore'\n",
    "            )\n",
    "\n",
    "        self.note_type_onehot.fit(np.array(NOTE_TYPES).reshape(-1, 1))\n",
    "        \n",
    "        # 位置编码器（假设位置范围是1-8）\n",
    "        positions = list(range(1, 9))  # maimai有8个位置\n",
    "        self.position_encoder = OneHotEncoder(\n",
    "            sparse_output=False,\n",
    "            dtype=np.float32,\n",
    "            handle_unknown='ignore'\n",
    "        )\n",
    "\n",
    "    def _encode_note_type(self, note_type):\n",
    "        \"\"\"将note类型编码为one-hot向量\"\"\"\n",
    "        return self.note_type_encoder.transform([[note_type]])[0]\n",
    "    \n",
    "    def _encode_position(self, position):\n",
    "        \"\"\"将位置编码为one-hot向量\"\"\"\n",
    "        return self.position_encoder.transform([[position]])[0]\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        json_file_name = self.json_paths[index]\n",
    "        json_file_path = os.path.join(self.serialized_dir, json_file_name)\n",
    "        \n",
    "        with open(json_file_path, 'r', encoding='utf-8') as f:\n",
    "            try:\n",
    "                json_data = json.load(f)\n",
    "            except json.JSONDecodeError as e:\n",
    "                raise ValueError(f\"JSON解析失败: {json_file_path}\") from e\n",
    "            \n",
    "            # 获取定数标签\n",
    "            song_id = int(json_data['song_id'])\n",
    "            level_index = int(json_data['level_index'])\n",
    "            difficulty_constant = self.label_map.get((song_id, level_index))\n",
    "            if difficulty_constant is None:\n",
    "                raise ValueError(f\"找不到对应的难度定数: song_id={song_id}, level_index={level_index}\")\n",
    "\n",
    "            # 加载谱面数据\n",
    "            note_groups = json_data.get('notes', [])\n",
    "            note_features_sequence = []\n",
    "            for note_group in note_groups:\n",
    "                time = note_group['Time']\n",
    "                notes = note_group['Notes']\n",
    "                for note in notes:\n",
    "                    note_type = note['Type']\n",
    "                    # 将note类型转换为数值编码\n",
    "                    note_type_encoded = self._encode_note_type(note_type)\n",
    "                    position = note['startPosition']\n",
    "                    # 将位置转换为数值编码\n",
    "                    position_encoded = self._encode_position(position)\n",
    "                    hold_time = note.get('holdTime', 0)\n",
    "                    is_break = int(note['isBreak'])\n",
    "                    is_ex = int(note['isEx'])\n",
    "                    is_slide_break = int(note['isSlideBreak'])\n",
    "                    slide_start_time = note['slideStartTime']\n",
    "                    slide_end_time = slide_start_time + note['slideTime']\n",
    "                    touch_area = self.touch_area_mapping[note['touchArea']]\n",
    "                    feature_vector = np.concatenate([\n",
    "                        [time],             # 1维\n",
    "                        note_type_encoded,  # 5维\n",
    "                        position_encoded,   # 8维\n",
    "                        [hold_time],        # 1维\n",
    "                        [is_break],         # 1维\n",
    "                        [is_ex],            # 1维\n",
    "                        [is_slide_break],   # 1维\n",
    "                        [slide_start_time], # 1维\n",
    "                        [slide_end_time],   # 1维\n",
    "                        [touch_area]        # 1维\n",
    "                    ]) # 总共 17维\n",
    "                    note_features_sequence.append(feature_vector)\n",
    "\n",
    "        # 将谱面数据转换为张量\n",
    "        note_features_tensor = torch.from_numpy(np.array(note_features_sequence, dtype=np.float32))\n",
    "        difficulty_constant_tensor = torch.tensor(difficulty_constant, dtype=torch.float32)\n",
    "        return note_features_tensor, difficulty_constant_tensor\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.json_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "22fa604e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['100018_LOVEYOU_6.json',\n",
       " '100018_LOVEYOU_DX_6.json',\n",
       " '100022_INCHAOS_6.json',\n",
       " '100022_INCHAOS_DX_6.json',\n",
       " '100114_SPACEHARRIERMAINTHEMEREBORN_6.json',\n",
       " '100199_チルノノハアフエクトサンスウキヨウシツ_6.json',\n",
       " '100199_チルノノハアフエクトサンスウキヨウシツ_DX_6.json',\n",
       " '100206_シユワスハタイサクセン_6.json',\n",
       " '100206_シユワスハタイサクセン_DX_6.json',\n",
       " '10021_コネクト_1.json']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "base_dir = os.path.dirname(os.path.abspath(''))  # 获取当前工作目录\n",
    "serialized_dir = os.path.join(base_dir, \"data\", \"serialized\")\n",
    "if not os.path.exists(serialized_dir):\n",
    "\tprint(f\"目录不存在: {serialized_dir} (当前工作目录: {os.getcwd()})\")\n",
    "\tjson_paths = []\n",
    "else:\n",
    "\tjson_paths = os.listdir(serialized_dir)\n",
    "json_paths[0:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dd0e33f",
   "metadata": {},
   "source": [
    "### 3.1 Note 属性编码\n",
    "\n",
    "将每个 note 的属性编码为固定维度的向量：\n",
    "\n",
    "**基础特征（每个 note）**：\n",
    "- **时间特征**：相对时间戳（相对于谱面开始时间）\n",
    "- **类型特征**：note 类型的 one-hot 编码（tap, hold, slide, break 等）\n",
    "- **位置特征**：按键位置（1-8）的 one-hot 编码或数值编码\n",
    "- **持续时间**：对于 hold 类型的 note，编码其持续时间\n",
    "- **时间间隔**（可选）：与前一个 note 的时间间隔\n",
    "\n",
    "**序列处理**：\n",
    "- **序列长度标准化**：使用 padding 或截断将所有序列调整为相同长度\n",
    "- **序列归一化**：对时间特征进行归一化处理（暂不处理）\n",
    "- **序列排序**：确保 note 按时间顺序排列（好像不需要）\n",
    "\n",
    "**TODO**：\n",
    "- 设计 note 特征的编码方案\n",
    "- 确定最佳的序列长度\n",
    "- 实现序列预处理管道\n",
    "- 考虑是否需要添加全局特征（如 BPM、总时长等）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "982a8fee",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2ec37d65",
   "metadata": {},
   "source": [
    "## 4. LSTM 模型构建与数据准备\n",
    "\n",
    "构建基于 LSTM 的时序模型来处理 note 序列数据。模型将接收形状为 `(batch_size, sequence_length, feature_dim)` 的输入，输出难度定数的预测值。\n",
    "\n",
    "**模型架构设计**：\n",
    "- **输入层**：接收编码后的 note 序列\n",
    "- **LSTM层**：捕捉序列中的时序依赖关系\n",
    "- **全连接层**：将 LSTM 输出映射到难度预测\n",
    "- **输出层**：回归输出，预测难度定数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77c3ed6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 合并特征和标签\n",
    "# full_df = pd.merge(feature_df, label_df, on='song_id')\n",
    "#\n",
    "# # 分离特征和目标变量\n",
    "# X = full_df.drop(['song_id', 'difficulty_constant'], axis=1).values\n",
    "# y = full_df['difficulty_constant'].values\n",
    "#\n",
    "# # 数据标准化\n",
    "# scaler = StandardScaler()\n",
    "# X_scaled = scaler.fit_transform(X)\n",
    "#\n",
    "# # 划分训练集和测试集\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)\n",
    "#\n",
    "# # 转换为 PyTorch Tensors\n",
    "# X_train_tensor = torch.tensor(X_train, dtype=torch.float32)\n",
    "# y_train_tensor = torch.tensor(y_train, dtype=torch.float32).view(-1, 1)\n",
    "# X_test_tensor = torch.tensor(X_test, dtype=torch.float32)\n",
    "# y_test_tensor = torch.tensor(y_test, dtype=torch.float32).view(-1, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a57606c6",
   "metadata": {},
   "source": [
    "### 4.1 定义 LSTM 模型架构\n",
    "\n",
    "**模型设计考虑**：\n",
    "- **多层 LSTM**：评估单层 vs 多层 LSTM 的效果\n",
    "- **Dropout**：防止过拟合\n",
    "- **Attention 机制**：突出重要的 note 序列部分\n",
    "\n",
    "**TODO**：\n",
    "- 实现基础的 LSTM 模型类\n",
    "- 设计模型的超参数（hidden_size, num_layers, dropout_rate）\n",
    "- 考虑添加注意力机制\n",
    "- 实验不同的模型架构"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e18abac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# class DifficultyPredictor(nn.Module):\n",
    "#     def __init__(self, input_features):\n",
    "#         super(DifficultyPredictor, self).__init__()\n",
    "#         self.layer1 = nn.Linear(input_features, 128)\n",
    "#         self.layer2 = nn.Linear(128, 64)\n",
    "#         self.output_layer = nn.Linear(64, 1)\n",
    "#         self.relu = nn.ReLU()\n",
    "\n",
    "#     def forward(self, x):\n",
    "#         x = self.relu(self.layer1(x))\n",
    "#         x = self.relu(self.layer2(x))\n",
    "#         x = self.output_layer(x)\n",
    "#         return x\n",
    "\n",
    "# # model = DifficultyPredictor(X_train_tensor.shape[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83eeaf44",
   "metadata": {},
   "source": [
    "## 5. 模型训练与优化\n",
    "\n",
    "**训练策略**：\n",
    "- **损失函数**：使用 MSE 或 MAE 损失函数（回归任务）\n",
    "- **优化器**：Adam 优化器，考虑学习率调度\n",
    "- **批次处理**：合理设置 batch_size 处理变长序列\n",
    "- **正则化**：Dropout + L2 正则化防止过拟合\n",
    "\n",
    "**训练监控**：\n",
    "- 训练损失和验证损失曲线\n",
    "- 早停机制防止过拟合\n",
    "- 学习率衰减策略\n",
    "\n",
    "**TODO**：\n",
    "- 实现训练循环\n",
    "- 设置验证集监控\n",
    "- 实现早停和模型保存机制\n",
    "- 调试序列批次处理中的 padding 问题\n",
    "- 优化训练超参数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07f4c4d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 定义损失函数和优化器\n",
    "# criterion = nn.MSELoss()\n",
    "# optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "#\n",
    "# # 训练循环\n",
    "# epochs = 100\n",
    "# for epoch in range(epochs):\n",
    "#     model.train()\n",
    "#     optimizer.zero_grad()\n",
    "#     outputs = model(X_train_tensor)\n",
    "#     loss = criterion(outputs, y_train_tensor)\n",
    "#     loss.backward()\n",
    "#     optimizer.step()\n",
    "#\n",
    "#     if (epoch+1) % 10 == 0:\n",
    "#         print(f'Epoch [{epoch+1}/{epochs}], Loss: {loss.item():.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19e27cee",
   "metadata": {},
   "source": [
    "## 6. 模型评估与性能分析\n",
    "\n",
    "**评估指标**：\n",
    "- **回归指标**：MSE, MAE, R²\n",
    "- **难度区间准确性**：预测值在真实值 ±0.1, ±0.2, ±0.5 范围内的比例\n",
    "- **分布分析**：预测值与真实值的分布对比\n",
    "\n",
    "**详细分析**：\n",
    "- **不同难度等级的预测准确性**：分析模型在低难度 vs 高难度谱面上的表现\n",
    "- **序列长度影响**：分析谱面长度对预测准确性的影响\n",
    "- **错误案例分析**：找出预测偏差较大的谱面特征\n",
    "\n",
    "**TODO**：\n",
    "- 实现全面的评估指标计算\n",
    "- 可视化预测结果分布\n",
    "- 分析不同难度区间的预测准确性\n",
    "- 进行错误案例的深入分析\n",
    "- 与传统特征工程方法进行对比"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0c76b12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.eval()\n",
    "# with torch.no_grad():\n",
    "#     predictions = model(X_test_tensor)\n",
    "#     test_loss = criterion(predictions, y_test_tensor)\n",
    "#     print(f'Test Loss: {test_loss.item():.4f}')\n",
    "#\n",
    "# # 可以在这里添加更详细的评估指标，例如 MAE, R^2 等"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f003fee0",
   "metadata": {},
   "source": [
    "## 7. 结果分析与模型迭代\n",
    "\n",
    "**深度分析**：\n",
    "- **时序特征的重要性**：LSTM 是否有效捕捉了时序信息\n",
    "- **不同 note 类型的影响**：哪些类型的 note 对难度预测更重要\n",
    "- **序列长度 vs 准确性**：最优的序列长度设置\n",
    "- **模型复杂度 vs 性能**：单层 vs 多层 LSTM 的权衡\n",
    "\n",
    "**模型优化方向**：\n",
    "- **架构改进**：考虑 Transformer、CNN-LSTM 混合架构\n",
    "- **特征增强**：是否需要添加手工特征作为辅助\n",
    "- **数据增强**：通过时间扭曲、音符变换等方式增加训练数据\n",
    "- **多任务学习**：同时预测难度和其他属性（如技巧需求）\n",
    "\n",
    "**TODO**：\n",
    "- 深入分析 LSTM 学到的时序模式\n",
    "- 可视化注意力权重（如果使用了注意力机制）\n",
    "- 比较不同模型架构的效果\n",
    "- 设计更鲁棒的数据增强策略\n",
    "- 考虑集成学习方法提升性能\n",
    "- 为生产环境部署准备模型压缩和优化"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3bf24c6",
   "metadata": {},
   "source": [
    "分析模型的预测结果，与真实定数进行比较。\n",
    "\n",
    "思考以下问题：\n",
    "- 模型的误差主要来自哪些谱面？\n",
    "- 是否有必要调整特征工程的方案？\n",
    "- 是否需要更复杂的模型结构？\n",
    "\n",
    "根据分析结果，回到前面的步骤进行迭代优化。\n",
    "\n",
    "**关键思考问题**：\n",
    "\n",
    "1. **时序建模的有效性**：\n",
    "   - LSTM 是否真的比传统统计特征更有效？\n",
    "   - 谱面的时序特征对难度的影响有多大？\n",
    "\n",
    "2. **数据表示的完整性**：\n",
    "   - 当前的 note 编码是否充分表达了游戏的复杂性？\n",
    "   - 是否遗漏了重要的游戏机制信息？\n",
    "\n",
    "3. **模型的可解释性**：\n",
    "   - 如何理解模型学到的难度判断规律？\n",
    "   - 能否提取出可解释的难度评估规则？\n",
    "\n",
    "4. **实际应用价值**：\n",
    "   - 模型的预测精度是否满足实际需求？\n",
    "   - 如何将模型集成到谱面制作工具中？\n",
    "\n",
    "**下一步迭代方向**：\n",
    "根据实验结果，有针对性地改进数据处理、模型架构或训练策略，最终目标是构建一个既准确又实用的难度预测系统。"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
